{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d0851c8d918f9ad433d63dff71dbacbe17259539d55e689a7d9cbf48e3dba898"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Limpieza de datos y agregaciones\n",
    "\n",
    "### OBJETIVO\n",
    "\n",
    "- Limpiar nuestros datasets de `NaNs`.\n",
    "- Reindexar si es necesario\n",
    "- Renombrar columnas si es necesario\n",
    "- Experimentar la aplicación de agregaciones para explorar nuestro dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Carga general de datos\n",
    "\n",
    "Para nuestra limpieza de datos, solo utilizaremos las siguientes librerias:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Vamos a realizar lo siguiente:\n",
    "\n",
    "- Cargar los documentos que limpiaremos, con el objetivo de dejar un par de archivos `csv` al final\n",
    "- Concentrar los datos por tipo de PM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PM10_2019 = pd.read_csv('../Datasets/PM10/2019PM10.csv') #Data PM 10 - 2019\n",
    "df_PM10_2020 = pd.read_csv('../Datasets/PM10/2020PM10.csv') #Data PM 10 - 2020\n",
    "df_PM25_2019 = pd.read_csv('../Datasets/PM2.5/2019PM25.csv') #Data PM 2.5 - 2019\n",
    "df_PM25_2020 = pd.read_csv('../Datasets/PM2.5/2020PM25.csv') #Data PM 2.5 - 2020"
   ]
  },
  {
   "source": [
    "Después de cargar nuestros archivos `csv`, los concatenamos para tener dos Dataframes (df), con los cuales vamos a realizar nuestra depuración de datos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PM10_total = pd.concat([df_PM10_2019 , df_PM10_2020], axis=0)\n",
    "df_PM25_total = pd.concat([df_PM25_2019 , df_PM25_2020], axis=0)"
   ]
  },
  {
   "source": [
    "## Depuración de archivos $PM_{10}$\n",
    "\n",
    "Comenzamos depurando la información de $PM_{10}$  \n",
    "De acuerdo a las especificaciones RAMA, los datos nulos se identifican con la etiqueta -99, por lo que, convertiremos los valores `-99` en `NaN`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PM10_total = df_PM10_total.replace(-99, np.nan)"
   ]
  },
  {
   "source": [
    "Haciendo una rápida validación de nuestro df que concentra los datos de $PM_{10}$, vemos que contiene **17,544** `filas` y **29** `columnas`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17544, 29)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_PM10_total.shape"
   ]
  },
  {
   "source": [
    "Ahora hacemos una revisión de los datos nulos que contiene nuestro df.   \n",
    "Podemos ver, que todas las filas y las columnas de las estaciones cuentan con al menos un valor `NaN`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17544"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Filas con NaN\n",
    "df_PM10_total.isna().any(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FECHA    False\n",
       "HORA     False\n",
       "ACO       True\n",
       "AJM       True\n",
       "ATI       True\n",
       "BJU       True\n",
       "CAM       True\n",
       "CHO       True\n",
       "CUA       True\n",
       "CUT       True\n",
       "FAC       True\n",
       "FAR       True\n",
       "GAM       True\n",
       "HGM       True\n",
       "INN       True\n",
       "IZT       True\n",
       "MER       True\n",
       "MGH       True\n",
       "MPA       True\n",
       "PED       True\n",
       "SAC       True\n",
       "SAG       True\n",
       "SFE       True\n",
       "TAH       True\n",
       "TLA       True\n",
       "TLI       True\n",
       "UIZ       True\n",
       "VIF       True\n",
       "XAL       True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Columnas con NaN\n",
    "df_PM10_total.isna().any()"
   ]
  },
  {
   "source": [
    "Revisando la parte proporcional de `NaNs` por cada columna, observamos que la mayoría de nuestras estaciones cuentan con un alto porcentaje de datos nulos.\n",
    "Y que la media de nuestras medias del df corresponde al **39.76%** de `NaN`. Una cifra bastante alta, por cierto."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FECHA    0.000000\n",
       "HORA     0.000000\n",
       "ACO      0.501482\n",
       "AJM      0.435192\n",
       "ATI      0.187699\n",
       "BJU      0.351231\n",
       "CAM      0.378819\n",
       "CHO      0.892613\n",
       "CUA      0.359211\n",
       "CUT      0.115367\n",
       "FAC      0.154925\n",
       "FAR      1.000000\n",
       "GAM      0.298792\n",
       "HGM      0.549248\n",
       "INN      0.342681\n",
       "IZT      0.234553\n",
       "MER      0.156692\n",
       "MGH      0.813383\n",
       "MPA      1.000000\n",
       "PED      0.109325\n",
       "SAC      1.000000\n",
       "SAG      0.428409\n",
       "SFE      0.120383\n",
       "TAH      0.339261\n",
       "TLA      0.222070\n",
       "TLI      0.615424\n",
       "UIZ      0.205882\n",
       "VIF      0.194140\n",
       "XAL      0.525992\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_PM10_total.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39.76818875104171"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_PM10_total.isna().mean().mean() * 100"
   ]
  },
  {
   "source": [
    "Considerando lo anterior, vamos a eliminar aquellas columnas que contengan al menos el **55%** de valores `NaNs`  \n",
    "Con esto, nos estamos quedando ahora con **23** columnas en total."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan con el 55% de NaN\n",
    "df_PM10_depurado = df_PM10_total.dropna(thresh=len(df_PM10_total)*0.45, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17544, 23)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_PM10_depurado.shape"
   ]
  },
  {
   "source": [
    "A pesar de que eliminamos columnas con un alto porcentaje de nulos, al validar nuestro df nuevamente, nos percatamos que todas nuestras filas tienen al menos un valor `NaN`, y ninguna fila con todos los valores `NaN`. Por lo tanto, no podemos eliminar las filas, debido a que nos estaríamos quedando sin datos para procesar.  \n",
    "Tampoco es posible, por esta estructura que tienen nuestros df, reemplazar estos valores `NaN` con 0, debido a que la naturaleza de nuestros análisis requieren obtener medias, y este valor nos estaría dando una tendencia errónea en nuestros resultados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17544"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_PM10_depurado[df_PM10_depurado.isna().any(axis=1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17544, 23)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df_PM10_depurado.dropna(axis=0, how='all').shape"
   ]
  },
  {
   "source": [
    "Realizamos un ejemplo de agregado (mean), que se puede aplicar a nuestro df depurado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HORA    12.500000\n",
       "ACO     47.815573\n",
       "AJM     33.896761\n",
       "ATI     38.657568\n",
       "BJU     32.202337\n",
       "CAM     42.013030\n",
       "CUA     32.840954\n",
       "CUT     46.794459\n",
       "FAC     34.396735\n",
       "GAM     43.321980\n",
       "HGM     41.718766\n",
       "INN     23.570239\n",
       "IZT     36.863728\n",
       "MER     46.755728\n",
       "PED     31.153718\n",
       "SAG     53.723175\n",
       "SFE     31.337740\n",
       "TAH     49.991373\n",
       "TLA     47.288247\n",
       "UIZ     41.892621\n",
       "VIF     49.135097\n",
       "XAL     67.097763\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_PM10_depurado.mean()"
   ]
  },
  {
   "source": [
    "Por último, guardamos nuestro df depurado en un nuevo `csv` de $PM_{10}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar csv\n",
    "df_PM10_depurado.to_csv('../Datasets/PM10/PM10_depurado.csv')"
   ]
  },
  {
   "source": [
    "## Depuración de archivos $PM_{2.5}$\n",
    "\n",
    "Ahora depuramos la información de $PM_{2.5}$  \n",
    "De acuerdo a las especificaciones RAMA, los datos nulos se identifican con la etiqueta -99, por lo que, convertiremos los valores `-99` en `NaN`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PM25_total = df_PM25_total.replace(-99, np.nan)"
   ]
  },
  {
   "source": [
    "Haciendo una rápida validación de nuestro df que concentra los datos de $PM_{2.5}$, vemos que contiene **16,800** `filas` y **26** `columnas`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16800, 26)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#Obtenemos las columnas\n",
    "df_PM25_total.shape"
   ]
  },
  {
   "source": [
    "Aplicamos la revisión de los datos nulos que contiene nuestro df.  \n",
    "Podemos ver que en este df, también todas las filas y las columnas de las estaciones cuentan con al menos un valor `NaN`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16800"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Filas con NaN\n",
    "df_PM25_total.isna().any(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FECHA    False\n",
       "HORA     False\n",
       "AJM       True\n",
       "AJU       True\n",
       "BJU       True\n",
       "CAM       True\n",
       "CCA       True\n",
       "COY       True\n",
       "FAR       True\n",
       "GAM       True\n",
       "HGM       True\n",
       "INN       True\n",
       "MER       True\n",
       "MGH       True\n",
       "MON       True\n",
       "MPA       True\n",
       "NEZ       True\n",
       "PED       True\n",
       "SAC       True\n",
       "SAG       True\n",
       "SFE       True\n",
       "SJA       True\n",
       "TLA       True\n",
       "UAX       True\n",
       "UIZ       True\n",
       "XAL       True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Columnas con NaN\n",
    "df_PM25_total.isna().any()"
   ]
  },
  {
   "source": [
    "Revisando la parte proporcional de `NaNs` por cada columna, observamos que la mayoría de nuestras estaciones también cuentan con un alto porcentaje de datos nulos.\n",
    "En este caso, la media de nuestras medias del df corresponde al **39.69%** de `NaN`. Una cifra igual de alta, por cierto."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FECHA    0.000000\n",
       "HORA     0.000000\n",
       "AJM      0.410179\n",
       "AJU      0.538036\n",
       "BJU      0.366667\n",
       "CAM      0.361071\n",
       "CCA      0.129524\n",
       "COY      1.000000\n",
       "FAR      0.149226\n",
       "GAM      0.311548\n",
       "HGM      0.529286\n",
       "INN      0.356250\n",
       "MER      0.161548\n",
       "MGH      0.805119\n",
       "MON      0.419345\n",
       "MPA      1.000000\n",
       "NEZ      0.209464\n",
       "PED      0.113393\n",
       "SAC      0.212500\n",
       "SAG      0.445952\n",
       "SFE      0.124643\n",
       "SJA      1.000000\n",
       "TLA      0.229643\n",
       "UAX      0.213512\n",
       "UIZ      0.208452\n",
       "XAL      0.505000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df_PM25_total.isna().mean()"
   ]
  },
  {
   "source": [
    "df_PM25_total.isna().mean().mean() * 100"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "37.69368131868132"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "source": [
    "Al igual que en nuestro df anterior, vamos a eliminar aquellas columnas que contengan al menos el **55%** de valores `NaNs`  \n",
    "Con esto, nos estamos quedando ahora con **22** columnas en total."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan con el 55% de NaN\n",
    "\n",
    "df_PM25_depurado = df_PM25_total.dropna(thresh=len(df_PM25_total)*0.45, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16800, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_PM25_depurado.shape"
   ]
  },
  {
   "source": [
    "En este caso, nos percatamos que salvo 2 filas, en este df las filas contienen al menos un valor `NaN`, y ninguna fila con todos los valores `NaN`. Por lo tanto, no podemos eliminar las filas, debido a que nos estaríamos quedando sin datos para procesar.  \n",
    "Tampoco es posible, por esta estructura que tienen nuestros df, reemplazar estos valores `NaN` con 0, debido a que la naturaleza de nuestros análisis requieren obtener medias, y este valor nos estaría dando una tendencia errónea en nuestros resultado."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16798, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df_PM25_depurado[df_PM25_depurado.isna().any(axis=1)].shape"
   ]
  },
  {
   "source": [
    "Realizamos un ejemplo de agregado (mean), que se puede aplicar a nuestro df depurado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HORA    12.500000\n",
       "AJM     19.096983\n",
       "AJU     18.674655\n",
       "BJU     18.110902\n",
       "CAM     22.833799\n",
       "CCA     19.181961\n",
       "FAR     18.966347\n",
       "GAM     22.199377\n",
       "HGM     24.675013\n",
       "INN     13.949145\n",
       "MER     23.063041\n",
       "MON     20.194567\n",
       "NEZ     24.976282\n",
       "PED     18.365760\n",
       "SAC     24.307181\n",
       "SAG     22.954340\n",
       "SFE     17.312593\n",
       "TLA     23.082367\n",
       "UAX     19.571634\n",
       "UIZ     21.539555\n",
       "XAL     26.067581\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df_PM25_depurado.mean()"
   ]
  },
  {
   "source": [
    "Por último, guardamos nuestro df depurado en un nuevo `csv` de $PM_{2.5}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar csv\n",
    "df_PM25_depurado.to_csv('../Datasets/PM2.5/PM25_depurado.csv')"
   ]
  },
  {
   "source": [
    "## Depuración de cat_estacion\n",
    "\n",
    "El siguiente archivo a depurar, es el catálogo de estaciones y zonas.  \n",
    "Cargamos nuestro archivo, y validamos "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_estacion = pd.read_csv('../Datasets/cat_estacion.csv') #Data catálogo de estaciones"
   ]
  },
  {
   "source": [
    "Haciendo una rápida validación de nuestro df con el catálogo de estaciones y zonas, vemos que contiene **69** `filas` y **8** `columnas`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(69, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "df_cat_estacion.shape"
   ]
  },
  {
   "source": [
    "Verificamos, cuántas filas y columnas cuentan con datos `NaN`  \n",
    "Confirmamos que en este df no tenemos tantos nulos, por lo que borraremos laa columnas que contengan datos `NaN` y que no hacen inferencia en nuestro análisis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "df_cat_estacion.isna().any(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cve_estac     False\n",
       "nom_estac     False\n",
       "longitud      False\n",
       "latitud       False\n",
       "alt            True\n",
       "obs_estac      True\n",
       "id_station    False\n",
       "Zona          False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "df_cat_estacion.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cve_estac     0.000000\n",
       "nom_estac     0.000000\n",
       "longitud      0.000000\n",
       "latitud       0.000000\n",
       "alt           0.014493\n",
       "obs_estac     0.710145\n",
       "id_station    0.000000\n",
       "Zona          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df_cat_estacion.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_estacion = df_cat_estacion.drop(['longitud','latitud','alt','obs_estac','id_station'], axis=1)"
   ]
  },
  {
   "source": [
    "Al final, después de depurar, solo nos quedamos con **3** columnas y ningún valor `NaN`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cve_estac    0.0\n",
       "nom_estac    0.0\n",
       "Zona         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df_cat_estacion.isna().mean()"
   ]
  },
  {
   "source": [
    "Guardamos nuestro nuevo catalogo de estaciones depurado en otro `csv`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_estacion.to_csv('../Datasets/cat_estacion_depurado.csv')"
   ]
  }
 ]
}